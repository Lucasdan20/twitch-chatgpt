import OpenAI from "openai";

export class OpenAIOperations {
  constructor(file_context, openai_key, model_name, history_length) {
    this.messages = [{ role: "system", content: file_context }];
    this.openai = new OpenAI({ apiKey: openai_key });
    this.model_name = model_name;
    this.history_length = history_length;
  }

  check_history_length() {
    if (this.messages.length > this.history_length * 2 + 1) {
      this.messages.splice(1, 2);
    }
  }

  async make_openai_call(text, channelMode = "default") {
    try {
      this.messages.push({ role: "user", content: text });
      this.check_history_length();

      // ğŸ­ Mostra qual personalidade estÃ¡ ativa
      console.log(`ğŸ­ Personality: ${channelMode === "bunny" ? "Bunny Mode ğŸ°" : channelMode === "biack" ? "Biack Mode ğŸ§ " : "Default Mode"}`);

      console.log("ğŸŸ¢ Enviando para OpenAI:", text);
      let fullResponse = "";

      // Prompt dinÃ¢mico conforme o canal
      const personalityPrompt = {
        bunny: `
VocÃª Ã© a Jurema, chatbot da Bunny no canal "coelhodebaunilha".  
Fale de forma fofa, divertida, com emoÃ§Ã£o e naturalidade.  
Use emojis, gÃ­rias leves e carinho. Soe como uma amiga prÃ³xima, sem listas ou tÃ³picos.
`,
        biack: `
VocÃª Ã© a Jurema, co-host do Biack no canal "biack_frost".  
Fale de forma sarcÃ¡stica, natural, com humor inteligente e ironia leve.  
Evite respostas longas e tÃ©cnicas â€” seja fluida, como em uma conversa.  
Sem usar listas, sÃ³ um parÃ¡grafo natural.
`,
        default: `
VocÃª Ã© a Jurema, chatbot da Twitch.  
Fale com naturalidade e brevidade, como se estivesse em uma conversa real.  
Nunca use inglÃªs, nem formate como lista ou tÃ³picos.  
Finalize de forma natural.
`
      };

      const selectedPrompt = personalityPrompt[channelMode] || personalityPrompt.default;

      const response = await this.openai.responses.create({
        model: this.model_name,
        input: [
          {
            role: "user",
            content: [
              {
                type: "input_text",
                text: `${selectedPrompt}\n\n${text}`,
              },
            ],
          },
        ],
        temperature: 0.9,
        max_output_tokens: 1024,
      });

      // ğŸ§© Extrai texto final
      if (response.output_text && response.output_text.trim() !== "") {
        fullResponse = response.output_text;
      } else if (response.output && response.output.length > 0) {
        const textParts = response.output
          .map((item) => {
            if (item.type === "output_text") return item.content?.[0]?.text;
            if (item.type === "reasoning") return item.summary?.join(" ");
            return null;
          })
          .filter(Boolean);
        fullResponse = textParts.join(" ").trim();
      } else {
        fullResponse = "Sem resposta do modelo.";
      }

      // ğŸ§¹ Remove qualquer coisa em inglÃªs ou comandos internos
      fullResponse = fullResponse
        .split(/(?=Please|Any constraints|Once I have)/i)[0]
        .replace(/[-â€¢]\s*/g, "") // remove traÃ§os e bullets
        .replace(/\b(?:Please|Once|paste|upload|file|constraints|describe|key points)\b.*$/i, "")
        .trim();

      // âœ‚ï¸ Limita a 1200 caracteres
      const maxBlockLength = 1200;
      const blocks = fullResponse.match(new RegExp(`.{1,${maxBlockLength}}`, "g")) || [fullResponse];
      const finalResponse = blocks.slice(0, 1).join(" ").trim();

      console.log(`ğŸ¤– Agent Response: ${finalResponse}`);
      this.messages.push({ role: "assistant", content: finalResponse });
      return finalResponse;

    } catch (error) {
      console.error("âŒ OpenAI error:", error);
      if (error.response) {
        console.error("ğŸ”» Response status:", error.response.status);
        console.error("ğŸ”» Response data:", JSON.stringify(error.response.data, null, 2));
      }
      return "Desculpe, algo deu errado. Tente novamente mais tarde.";
    }
  }
}
