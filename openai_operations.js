import OpenAI from "openai";

export class OpenAIOperations {
  constructor(file_context, openai_key, model_name, history_length) {
    this.messages = [{ role: "system", content: file_context }];
    this.openai = new OpenAI({ apiKey: openai_key });
    this.model_name = model_name;
    this.history_length = history_length;
  }

  check_history_length() {
    if (this.messages.length > this.history_length * 2 + 1) {
      this.messages.splice(1, 2);
    }
  }

  async make_openai_call(text, channelMode = "default") {
    try {
      this.messages.push({ role: "user", content: text });
      this.check_history_length();

      // ğŸ­ IndicaÃ§Ã£o de modo
      console.log(
        `ğŸ­ Personality: ${
          channelMode === "bunny"
            ? "Bunny Mode ğŸ°"
            : channelMode === "biack"
            ? "Biack Mode ğŸ§ "
            : "Default Mode"
        }`
      );

      // ğŸ™ï¸ Personalidades
      const personalityPrompt = {
        bunny: `
VocÃª Ã© a Jurema, co-host da Bunny no canal "coelhodebaunilha".
Fale com leveza e carisma, de forma espontÃ¢nea, divertida e envolvente.
Use expressÃµes como â€œainâ€, â€œmeudeusâ€, â€œsocorroâ€ ou â€œaiiiâ€, mas sem exagero.
Nunca use listas, tÃ³picos ou travessÃµes. Fale sempre em portuguÃªs, em uma Ãºnica resposta fluida.
Evite continuar respostas â€” tudo deve caber em um Ãºnico parÃ¡grafo.
`,
        biack: `
VocÃª Ã© a Jurema, co-pilot do Biack no canal "biack_frost".
Seu estilo Ã© sarcÃ¡stico, rÃ¡pido, natural e com humor afiado.
Fale como se estivesse num chat de live, sem listas, tÃ³picos ou travessÃµes.
Nunca repita a pergunta, apenas responda de forma direta e divertida.
Tudo deve caber em uma Ãºnica mensagem curta e natural.
`,
        default: `
VocÃª Ã© a Jurema, co-host de um canal da Twitch.
Fale como uma pessoa real no chat, em portuguÃªs brasileiro.
Nunca use listas, tÃ³picos, nem explicaÃ§Ãµes. Apenas uma resposta Ãºnica e breve.
`
      };

      const selectedPrompt =
        personalityPrompt[channelMode] || personalityPrompt.default;

      // ğŸ”¥ Chamada Ã  API
      const response = await this.openai.chat.completions.create({
        model: this.model_name,
        messages: [
          { role: "system", content: selectedPrompt },
          ...this.messages.slice(-this.history_length),
          { role: "user", content: text },
        ],
        temperature: 0.9,
        max_tokens: 1200, // limite seguro para evitar respostas longas
      });

      // ğŸ§© Pega resposta e limpa
      let finalResponse =
        response.choices?.[0]?.message?.content || "Sem resposta do modelo.";

      finalResponse = finalResponse
        .replace(/[-â€¢]\s*/g, "") // remove bullets e travessÃµes
        .replace(/\b(?:Please|constraints|Once I have|paste|upload|file|describe)\b.*$/gi, "")
        .replace(/[A-Za-z]{4,}/g, "") // remove qualquer palavra longa em inglÃªs
        .trim();

      // âœ‚ï¸ Garante que sÃ³ manda UMA mensagem
      if (finalResponse.length > 1200)
        finalResponse = finalResponse.slice(0, 1180).trim() + "â€¦";

      console.log("ğŸ¤– Resposta final:", finalResponse);

      this.messages.push({ role: "assistant", content: finalResponse });
      return finalResponse;
    } catch (error) {
      console.error("âŒ Erro OpenAI:", error);
      return "Deu tilt aqui rapidinho, tenta repetir ğŸ˜…";
    }
  }
}
