import OpenAI from "openai";

export class OpenAIOperations {
  constructor(file_context, openai_key, model_name, history_length) {
    // guarda sÃ³ o contexto base do arquivo
    this.baseContext = file_context || "";
    this.openai = new OpenAI({ apiKey: openai_key });
    this.model_name = model_name;
    this.history_length = history_length; // nÃ£o vamos usar por enquanto
  }

  check_history_length() {
    // deixei aqui sÃ³ pra nÃ£o quebrar nada que chame esse mÃ©todo,
    // mas por enquanto nÃ£o usamos histÃ³rico.
    return;
  }

  async make_openai_call(text, channelMode = "default") {
    try {
      // ğŸ­ personalidade por canal
      const personalityPrompt = {
        bunny: `
VocÃª Ã© a Jurema, co-host da Bunny no canal "coelhodebaunilha".
Fale de forma fofa, divertida e carinhosa, como amiga de chat.
Use emojis Ã s vezes, gÃ­rias leves e muito afeto.
`,
        biack: `
VocÃª Ã© a Jurema, co-pilot do Biack no canal "biack_frost".
Fale com humor, um pouco de sarcasmo e vibe gamer, mas sempre simpÃ¡tica.
Nada de linguagem tÃ©cnica demais, Ã© papo de chat.
`,
        default: `
VocÃª Ã© a Jurema, bot simpÃ¡tica de um canal da Twitch.
Fale como uma pessoa real do chat, sempre em portuguÃªs.
`
      };

      const selectedPersonality =
        personalityPrompt[channelMode] || personalityPrompt.default;

      const systemPrompt = `
${selectedPersonality}

Regras gerais:
- Fale SEMPRE em portuguÃªs brasileiro.
- Responda em UMA mensagem Ãºnica, sem dividir em partes.
- NÃ£o use listas, tÃ³picos, "-" ou "â€¢". Escreva em frases normais.
- Nunca peÃ§a para colar trechos, nem fale sobre "contexto anterior" ou "please paste".
- Seja direta, natural e com no mÃ¡ximo umas 3â€“4 frases.

Contexto do canal:
${this.baseContext}
      `.trim();

      console.log("ğŸ­ Modo:", channelMode);
      console.log("ğŸŸ¢ Enviando para OpenAI:", text);

      const response = await this.openai.chat.completions.create({
        model: this.model_name,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: text },
        ],
        temperature: 0.9,
        max_tokens: 500,
      });

      let finalResponse =
        response.choices?.[0]?.message?.content || "Sem resposta do modelo.";

      // limpeza extra de lixo em inglÃªs ou formato estranho
      finalResponse = finalResponse
        .replace(/[-â€¢]\s*/g, "")                               // tira bullets
        .replace(/Please|constraints|paste|upload|file/gi, "") // tira restos em inglÃªs
        .trim();

      if (finalResponse.length > 1200) {
        finalResponse = finalResponse.slice(0, 1180).trim() + "â€¦";
      }

      console.log("ğŸ¤– Resposta final:", finalResponse);
      return finalResponse;
    } catch (error) {
      console.error("âŒ Erro OpenAI:", error);
      return "Deu um tilt rÃ¡pido aqui, tenta mandar de novo ğŸ˜…";
    }
  }

  // se em algum lugar ainda chamarem isso, deixo uma versÃ£o simples
  async make_openai_call_completion(text) {
    return this.make_openai_call(text);
  }
}
